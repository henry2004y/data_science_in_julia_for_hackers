[
    [
        "optimal-pricing.html",
        "Chapter 9 Optimal pricing 9.1 Overview 9.2 Optimal pricing 9.3 Maximizing profit 9.4 Summary 9.5 References",
        " Chapter 9 Optimal pricing 9.1 Overview In a bayesian framework we can work intrinsically with the uncertainty of the data. It allows us to include it in our models. This is especially beneficial when we want to take a decision based on the results of a model. In this type of problem, if we optimize the expected value of the function we want to maximize, we obtain just a number, losing all the information and richness uncertainty can give us. In real-life scenarios, when making decisions we almost never have all the necessary information and therefore we have to deal with uncertainty. So it’s important to be able to take into account how certain we are of the information we have. It may be the case that the value that maximizes (or minimize) certain problem comes with a lot of uncertainty so it would be more appropriate to choose other with a better optimization-uncertainty trade off. Bayesian inference allows us to do this because of it approach of a statistical problem. From its point of view, the data obtained on an event is fixed. They are observations that have already happened and there is nothing stochastic about it. So the data is deterministic. On the contrary, the parameters of the models we propose to describe such data are stochastic, following a given probability distribution. In this way, the inference that is made is on the complete distributions of our parameters, which allows us, precisely, to include the uncertainty into our models. Before starting we want to thank Chad Scherrer since this chapter is inspired by his article 9.2 Optimal pricing Pricing a product is not an easy task. Multiple factors intervene in a customer’s decision to buy a product. Also, a price can be fixed for some unknown business’ decision. Now suppose you have a new product you want to introduce in the local market and you need to set a price for it. Also, as a businessman, you want to have the maximum profit. If the kind of product you intend to produce were already in the market, you could use this information to have an initial guess. If the price is too high, you probably won’t sell much. Conversely, if it’s too low, you probably sell more, but since the production process has an associated cost, you have to be careful and take it into account when you do the math. Let’s import the packages we will be using through the chapter using Plots using Turing using StatsPlots using LaTeXStrings 9.2.1 Price vs Quantity model We are going to use a known equation to model the relationship between price of a product and the quantity demanded, the equation \\(Q = aP^{c}\\) Figure 1 shows its behavior for some value of a and c. This equation tells us that the higher the price, the less we sell, and if we continue rising the price, eventually our product it’s so expensive that nobody is interested. a = 5000 c = -0.5 P = 1:100 Q = a.*(P.^c) plot(P, Q, legend=false, title=&quot;quantity vs price model&quot;)#: $Q=aP^c$&quot;); xlabel!(&quot;price&quot;); ylabel!(&quot;quantity&quot;) You can imagine this as when you buy a luxury bread at the bakery: In the beginning, if the price of this bread is very low and you will surely buy many of them, even giving some away so that others can try them. If one day you wake up and see that the price of this tasty bread is now double, you will surely stop buying too much and just concentrate on having it for a nice breakfast. Now, if a couple of months later the bakery became famous thanks to its delicious bread and they decided to sell it five times more expensive than before, you would start looking for another bakery. 9.2.1.1 Power law distributions Okay, so we agree that our model has to express that as the price goes up the quantity tends to go down. However, one could ask why use a decreasing exponential function and not another one, for example a linear relationship with a negative slope. The answer to this question is not straightforward. To start building an intuition, we must think about how people’s income is distributed. Surely many of you have the main idea: income is not distributed equally across the population. In general, a few people concentrate most of the income, and only a little of the income is distributed in the majority of the population. The distributions that describe this phenomenon are called ‘power laws’. The best known is perhaps the Pareto distribution or 80-20 distribution. A distribution widely used in business management referring to the fact that, for example, 20% of the mix of products sold are those that generate 80% of the profits. In economics this idea is presented with the Lorenz curve: function lorenz(y) n = length(y) y = sort(y) s = zeros(n + 1) s[2:end] = cumsum(y) cum_people = zeros(n + 1) cum_income = zeros(n + 1) for i in collect(1:n) cum_people[i] = i / n cum_income[i] = s[i] / s[n] end return cum_people, cum_income end w = exp.(randn(100)); f_vals, l_vals = lorenz(w); plot(f_vals, label=&quot;Lorenz curve&quot;,l_vals, l=3,xlabel=&quot;Cumulative population&quot;, xaxis=0:0.1:1); plot!(f_vals, label=&quot;Perfect equality&quot;, f_vals, l=3, ylabel=&quot;Cumulative income&quot;, yaxis=0:0.1:1) Lorenz curve. A graphical representation of income inequality. In this graph, the x-axis represents the accumulated population and the y-axis the accumulated income. Going from left to right and as you move along the x-axis, more and more income is accumulated by fewer people. For example, the first 10% of the population barely accumulates 1% of income while the richest 10% on the right accumulates 40%. An ideal society with a perfectly distributed income would have a straight 45º Lorenz curve. With this in mind we can already generate an intuition that will help us answer the initial question: why use a decreasing exponential and not a negative-slope line? Since a great majority of people have a small relative income and a minority has a large one, as we increase the price of the product, a large number of people with low income can no longer afford it. This process continues until only people with a high income are left and their consumption preferences are not greatly affected by the price increase. The exponential distribution is useful to describe this. 9.2.2 Price elasticity of demand A very important factor to consider is the price elasticity of demand of the product in question. What does this mean? It relates how much the quantity demanded by customers of a product changes when its price is changed by one unit. Mathematically, price elasticity is defined as: \\(e_{(p)}=\\frac{dQ/Q}{dP/P}\\) For example, the price elasticity of demand of a medicine for a terminal illness is not the same as that of chocolate with peanuts. While some might argue that chocolate is vital for their life, the difference between these two products is that users of the medicine cannot afford not to consume it. No matter how much the price increases, the nature of their need forces them to buy it anyway. It is said then that the medicine is inelastic, that is, it is not sensitive to price. a = 500 c = -0.05 P = 1:100 Q = a .+ c.*P plot(P, Q, legend=false, ylims = (400,550)); xlabel!(&quot;price&quot;); ylabel!(&quot;quantity&quot;) Inelastic demand of an important medicine. As it is vital for life the price hardly affects the quantity demanded On the contrary, if we see that the price of chocolates goes up a lot, we will probably stop consuming it, since it is not vital for our health. Well, that’s relative. a = 500 c = -0.9 P = 1:100 Q = a.*(P.^c) plot(P, Q, legend=false); xlabel!(&quot;price&quot;); ylabel!(&quot;quantity&quot;) Possible demand curve for non chocolate lovers. As the price goes up the quantity goes down a lot. Perhaps you are wondering the importance of being able to have clarity about the elasticity of a product. To explain it, let’s remember how the sales (in money) we get when trading a product are calculated: \\(sales = quantity * price\\) So it is vitally important to analyze how much one variable varies when moving the other. It is evident that in the case of inelastic goods, it is always convenient to raise the price in terms of increasing the profit. On the other hand, when we work with a good that has some kind of elasticity, the increase generated by setting a higher price can be offset by an even greater drop in the amount sold. So we have to understand very well that behavior in order to define the optimal price level. 9.2.2.1 Dealing with uncertanty Anyway, if our product is a new idea, the problem depicted above gets a lot more complicated if the product is brand new, an invention, and the approach it’s different. That’s the problem we are about to solve: Suppose you are about to release a completely new and disrupting product. Your product is so different that you don’t have others to compare with, at least in the local market, so you are not sure about what price to choose. You don’t want to lose money of course, so you want the maximum profit you could get. To test the waters, a common choice is to run a pilot test, offering your product at different prices and see how customers react. So you record how much you sell at what price, but how do we proceed? Now, given the model and the data available, we define it So, given our exponential model to describe the relationship between the price of a good and the quantity demanded, we want to estimate its parameters: \\(Q = aP^{c}\\) In order to do this, an intelligent strategy is to linearize the relationship in order to perform a simple linear regression. Simply taking the logarithm of both sides of the equation achieves the goal: \\(\\log(Q) = \\log(a) + c\\log(P)\\) Now, the only thing left to do is to define the model in a bayesian framework for Julia, called Turing, which is used to do probabilistic programming. @model function quantity(qval, p0) log_a ~ Cauchy() c ~ Cauchy() log_μ0 = log_a .+ c*(log.(p0) .- mean(log.(p0))) μ0 = exp.(log_μ0) for i in eachindex(µ0) qval[i] ~ Poisson(μ0[i]) end end How do we interpret this model? 9.2.2.2 Priors: our previous knowledge Remember that Bayesian models always ask us to choose previous distributions for their parameters. In this particular example we propose that log a and c follow a Cauchy distribution. Why did we do this? Basically they are very flat distributions that are going to leave a lot of freedom for the model to learn from the data what the value of the parameters are. plot(-10:0.01:10, Cauchy(), xlim=(-10, 10), label=&quot;Cauchy(0, 1)&quot;); plot!(Normal(), xlim=(-10,10), label=&quot;Normal(0,1)&quot;); xlabel!(&quot;x&quot;); ylabel!(&quot;Probability density&quot;) Normal and Cauchy distributions. The Cauchy distribution is said to be fat tailed as it allows for extreme values Is doing this the best choice? Definitely not. Having the possibility to choose the previous distributions allows us to introduce previous knowledge to our problem. For example, if you were doing a linear regression to find the relationship between people’s weight and their height, you could already “tell” the model that it would not make sense for the relationship to be negative, that is, it does not seem right to affirm that as a person weighs more, he or she would be shorter. Another very important use of priors is to define the scale of the problem. In the example of height and weight it would be useful to say something like ‘It doesn’t make sense that for every additional kilogram of weight, a person will measure one meter more. At most a few centimeters’. All this information can be communicated to our model through the priors we choose. Let’s leave it there for now. Returning to the code. Julia allows us to easily define the variables that are probability distributions using the ~ operator. Once we know c and log a for a given value of price, we can univocally determine the quantity, therefore the variables \\(\\log(\\mu_0)\\) (and \\(\\mu_0\\)) are defined with the = operator, indicating a deterministic relation. In addition, since the quantity of product sold is a discrete one and it comes from adding independent purchases, they are modeled as a poisson distribution. But why do we subtract the mean for the price values? It´s a good practice to avoid a common problem: multicollinearity. With multicollinearity, the models tend to be more certain about the plausible values of our model, meanwhile models with more normalized data are more conservative and they are less prone to overfitting, an unwanted effect we need to avoid if we expect our model to work good with new. As a rule of thumb, it is always good to standardize our data. That is, subtract their average and divide each by its standard deviation. 9.2.2.3 Updating our beliefs In our problem, we said we have already recorded some points of the curve for our product. And to do it we simply run the pilot test, fixing a price and counting the amount of product we sold. We can infer employing this data the “demand curve”, then we can propose a profit function for the new product and finally find the price that maximizes our profit. In the figure 2 we plot the points recorded in the pilot test. At first sight they seem to follow the expected relationship but it is not a perfect curve, right? They have some kind of “noise”. Well, after all we could say that the reality is noisy. # Our points from the pilot test price = [1500, 2500, 4000, 5000] quant = [590, 259, 231, 117] scatter(price, quant, markersize=6, color=&quot;orange&quot;, legend=false, xlim=(1000,6000), ylim=(0,1100)); xlabel!(&quot;price&quot;); ylabel!(&quot;quantity&quot;) As we said, in a bayesian framework our previous knowledge are the distributions we propose for each of the parameters and the relationship known between price and quantity. With this bayesian approach, our previous knowledge are the distributions we propose for each of the parameters and the relationship known between price and quantity. What we do now is to update our believes, incorporating in our model the data points we have recoded from our pilot test as show in the code bellow, instantiating our model with the points quantity and price. Our model now has computed what is called the posterior distributions for the parameters log a and c, our updated beliefs for the plausible values for this two parameters. model = quantity(quant, price) posterior = sample(model, NUTS(), 1000) post_loga = collect(get(posterior, :log_a)) post_c = collect(get(posterior, :c)) hist_loga = histogram(post_loga, normed=true, bins=20, label = false, xlabel=&quot;log a&quot;); hist_c = histogram(post_c, normed=true, legend=false, bins=20, xlabel=&quot;c&quot;); plot(hist_loga, hist_c, layout=(1,2)) Posterior distributions for the parameters log a and c. Let’s stop for a moment and analyze this. We defined our model and asked turing to return the best possible estimate of our parameters, taking into account our initial beliefs and the information obtained from the pilot test, and what Turing returns was a distribution of possibilities for those parameters. But, our model is defined by a single value of a and c. So what do we do? One option would be to take the mean of our distributions. mean(post_loga[1]) ## 5.546905134831591 mean(post_c[1]) ## -1.1772082045306818 So \\(\\log(a)\\) would be 5.55 and c -1.18, and we should only have to replace those values in our model equation to get the answer to our problem: \\(\\log(Q)=5.55 - 1.18\\log(P)\\) This would make sense? Not even close. By doing this we would be throwing away a lot of precious information that the Bayesian framework gives us: The uncertainty about our inference. 9.2.2.4 Making uncertainty our ally Instead of getting rid of the uncertainty of our measurements, we have to use them to our advantage. This way instead of keeping only one model, we will use all possible models that can be built having the distributions of their parameters. That is, to sample our parameter distributions and build different models with each combination of them. Let’s see it: p = range(1000, 9000, step = 10); q = zeros(length(p), length(post_c[1])) for i in collect(1:length(post_c[1])) q[:,i] = exp.(post_loga[1][i] .+ post_c[1][i] .* (log.(p) .- mean(log.(price)))) end Here we are creating an array of as many rows as price values we want to observe and with as many columns as samples we have of each of our log and c parameters, that is, as many columns as models we have at our disposal. Let´s plot them all and se what happen: plot(p,q[:,1], xlim=(1000,6000)); for i in collect(1:length(post_c[1])) plot!(p,q[:,i], color=&quot;blue&quot;, legend=false, alpha = 0.1) end plot!(p, mean(q, dims=2), color=&quot;red&quot;, lw=2); scatter!(price, quant, color=&quot;orange&quot;, markersize=5); ylabel!(&quot;quantity&quot;); xlabel!(&quot;price&quot;) In this way we can visualize all the possible models that our Bayesian inference gives us. Since values of log a and c with higher probability will be sampled more often, the density of lines give us a sense of plausibility, and therefore we can evaluate the certainty (or uncertainty) of our model for a given value of price. We also highlight in red the average quantity obtained taking into account all the different models. As a last check (even if we have already taken preventive measures), we want to make sure that our model parameters do not share information. That is, we want to check that there is no collinearity between them. To evaluate multicollinearity between the two parameters of our model, we plot the sampled values, one against the other. In the figure 4, we don’t see a pattern, they seem to be decorrelated, therefore multicollinearity is not present in our model, so we are good to go and we can continue with the problem. scatter(post_loga, post_c, legend=false); xlabel!(&quot;log a&quot;); ylabel!(&quot;c&quot;) Parameters c vs log a for sampled values from the posterior distributions. As you can see, the point cloud is well dispersed so multicollinearity is not going to be a problem for us. 9.3 Maximizing profit Now that we have estimated our posterior distributions, we will try to answer the following question: what is the price that will give us the maximum profit? This is why we calculated the relationship between the price and the quantity of our product. As we said before, depending on that relation, it was going to be possible to define an optimal price point. Now we only have to add one more part to the equation: the production costs. Having this, we will be able to set up our profit function that will tell us, for each price we choose, how much money we would expect to earn. So let´s define it: As many of you know, the profit on the sale of a product is calculated as income minus costs. \\(profit=price * quantity - cost\\) But also the cost can be divided between the one that doesn’t depend on the production and I always have, and the one that does. For example, the costs of renting the warehouse, the salaries of the administrative workers or the insurance will not vary if 3000 or 5000 units are produced. This is why they are called fixed costs. On the other hand, the costs of raw materials, packaging or distribution; if they depend on the quantity produced, so they are included in variable costs. \\(profit = price * quantity - (variable cost * quantity + fixed cost)\\) fixed_cost = 10000 k = 700 var_cost = k .* q total_cost = var_cost .+ fixed_cost profit = p .* q .- total_cost Now we can plot the profit for many sampled values from the posterior distributions of our model and find the maximum. max_val, max_idx = findmax(mean(profit, dims=2); dims=1); max_val[1] ## 581902.150575046 With the unfavorable (or favorable) case of: unfav = max_val[1] - std(profit[max_idx[1][1], :]) ## 551634.8297664977 fav = max_val[1] + std(profit[max_idx[1][1], :]) ## 612169.4713835942 s = latexstring(&quot;\\\\mu_{profit}&quot;) s2 = latexstring(&quot;\\\\mu_{profit} \\\\pm \\\\sigma{profit}&quot;) s3 = latexstring(&quot;ArgMax(\\\\mu_{profit})&quot;) plot(p, mean(profit, dims=2) + std(profit, dims=2), color = &quot;orange&quot;, lw=2, label =s2); plot!(p, mean(profit, dims=2), color = &quot;red&quot;, lw=4, label=&quot;&quot;); for i in collect(1:length(post_c[1])) plot!(p, profit[:,i], color=&quot;blue&quot;, label=false, alpha = 0.1); end plot!(p, mean(profit, dims=2), color = &quot;red&quot;, lw=4, label=s); plot!(p, mean(profit, dims=2) - std(profit, dims=2), color = &quot;orange&quot;, lw=2, label=&quot;&quot;); vline!(p[max_idx], p[max_idx], line = (:black, 3), label=s3); xlabel!(&quot;price&quot;); ylabel!(&quot;profit&quot;); plot!(legend=true) Profit for sampled values, highlighting the mean, a deviation from the mean and the maximum mean profit. In this way, not only do we have the information about the average profit (marked in red), but we also have a notion of the uncertainty that the model handles. As you can see in the graph and remembering that the highest price value we had in the pilot test was $5000, the uncertainty increases a lot for higher values, reflecting the lack of data. Then, analyzing the graph: The red line plotted is the mean expected profit and its maximum is near $4840. The region between the orange lines is approximately one standard deviation far from the expected value or where the 65% of the lines, plotted from the sampled values of our parameters, fall. With this in mind and seeing that the profit curve is quite flat in the sector where the maximum is found, one could argue that it is preferable to choose a lower price since since the money lost would be minimal, but the volatility would go down considerably. In order to see this, it would be interesting to graph the standard deviation of the profit according to the price we choose: std_p = [std(profit[i, :]) for i in collect(1:length(p))] plot(p, std_p, legend=false, xlabel = &quot;Price&quot;, ylabel= &quot;Std deviation of profit&quot;, lw=2) Looking at both graphs we can see that, while the average profit is flattened, the standard deviation of it always goes up, corroborating that lowering the price can be a good strategy For example, let’s look at the case where an alternative price of $4000 is chosen: quantity_at_4000 = q[findfirst(isequal(4000), p), :] # Sales minus costs for every model at price of $4000 profit_4000 = 4000 .* quantity_at_4000 .- (10000 .+ quantity_at_4000 .* 700) #A faster way: prof_4000 = profit[findfirst(isequal(4000), p), :] mean_prof_4000 = mean(profit_4000) ## 580200.7024001909 With the unfavorable (or favorable) case of: unfav_4000 = mean(profit_4000) - std(profit_4000) mean(profit_4000) + std(profit_4000) ## 605916.6825987133 plot(p, mean(profit, dims=2) + std(profit, dims=2), color = &quot;orange&quot;, lw=2, label=s2); plot!(p,mean(profit, dims=2), color = &quot;red&quot;, lw=4, label=&quot;&quot;); for i in collect(1:length(post_c[1])) plot!(p,profit[:,i], color=&quot;blue&quot;, label=false, alpha = 0.1); end plot!(p,mean(profit, dims=2), color = &quot;red&quot;, lw=4, label=s); plot!(p,mean(profit, dims=2) - std(profit, dims=2), color = &quot;orange&quot;, lw=2, label=&quot;&quot;); vline!([4000], [4000], line = (:purple, 3), label=false); vline!(p[mxindx], p[mxindx], line = (:black, 3), label=s3); xlabel!(&quot;price&quot;); ylabel!(&quot;profit&quot;); plot!(legend=true) Then, by choosing a price of $4000 the average profit goes from $582800 to $58120. That is, a percentage variation of: porcentual_profit_diff = ((mean(profit_4000) - max_val[1]) / max_val[1]) * 100 ## -0.2923942063409954 While the most unfavorable case goes from $549705 to $553298.5. That is, a percentage variation of: porcentual_std_diff = ( unfav_4000 - unfav) / unfav *100 ## 0.5166266307689537 porcentual_std_diff / porcentual_profit_diff ## -1.7668839517512682 So, for every dollar we “lost” in average profitability, we gained more than double in the reduction of uncertainty. Regardless of each person decision, the important thing about the Bayesian framework is that it allows us to include uncertainty in our models and use it to our advantage to make more informed and intelligent decisions. Instead of wanting to forget and get rid of uncertainty, Bayesianism allows us to accept that this is an inherent feature of reality and to take advantage of it. Being able to narrow down how sure we are about the inferences we make gives us an invaluable advantage when making decisions. 9.4 Summary In this chapter we have learned some basics concepts of economics such as the price elasticity of demand for a product, or the Pareto distribution of income and wealth. Then, we estimated the demand curve of a possible new product, performing a pilot test to see the relationship between price and quantity demanded. Thanks to Bayesian inference we were able to use the uncertainty we had to our advantage, quantifying the trade-off between expected return and the variability of it, making possible to perform a well informed decision. 9.5 References Chad Scherrer Bayesian Optimal Pricing Post "
    ],
    [
        "404.html",
        "Page not found",
        " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "
    ]
]
[
    [
        "basketball-shots.html",
        "Chapter 8 Basketball shots 8.1 Modelling the scoring probability 8.2 Prior Predictive Checks: Part I 8.3 New model and prior predictive checks: Part II 8.4 Does the Period affect the scoring probability? 8.5 Summary",
        " Chapter 8 Basketball shots When playing basketball we can ask ourselves: how likely is it to score given a position in the court? To answer this question we are going to use data from NBA games from the 2006 - 2007 season. Lets load the data into our Julia session and inspect the column names: shots = CSV.read(&quot;./08_basketball_shots/data/seasons/shots_season_2006_2007.csv&quot;, DataFrame); names(shots) ## 5-element Vector{String}: ## &quot;result&quot; ## &quot;x&quot; ## &quot;y&quot; ## &quot;period&quot; ## &quot;time&quot; The columns of our dataset are the following: result: Stores a 1 if the shot was successful and a 0 otherwise. x: The x-component of the position of the player when the shot was made. y: The y-component of the position of the player when the shot was made. period: Indicates in which of the four periods of a basketball game the shot was done. time: The exact time the shot was made. Below we show a sketch of a basketball court, its dimensions and how to interpret the data in the table. It would be useful to change the shot coordinates from cartesian (x and y coordinates) to polar. In this way, we can think about the problem considering the distance and the angle from the hoop. shots[!, :distance] = sqrt.( shots.x .^ 2 + shots.y .^ 2) shots[!, :angle] = atan.( shots.y ./ shots.x ) filter!(x -&gt; x.distance &gt; 1, shots) So, the \\(x\\) and \\(y\\) axis have their origin at the hoop, and we compute the distance from this point to where the shot was made. Also, we compute the angle with respect to the \\(x\\) axis, showed as θ in the sketch. Lets now plot where the shots were made with a two-dimensional histogram. As more shots are made in a certain region of the field, that region is shown with a brighter color. histogram2d(shots.y[1:10000], shots.x[1:10000], bins=(50,30)); xlabel!(&quot;x axis&quot;); ylabel!(&quot;y axis&quot;) We see that the shots are very uniformly distributed around the hoop, except for distances very near to the hoop. To see this better, we plot the histograms for each axis, \\(x\\) and \\(y\\). As we are interested in the shots that were scored, we filter the shots made and plot the histogram of each axis. shots_made = filter(x -&gt; x.result == 1, shots) histogram(shots_made.y[1:10000], legend=false, nbins=40); xlabel!(&quot;x axis&quot;); ylabel!(&quot;Counts&quot;) histogram(shots_made.x[1:10000], legend=false, nbins=45); xlabel!(&quot;y axis&quot;); ylabel!(&quot;Counts&quot;) We can also summarize all this information with a wireplot, as shown below h = fit(Histogram, (shots_made.y, shots_made.x), nbins=40); wireframe(midpoints(h.edges[2]), midpoints(h.edges[1]), h.weights, zlabel=&quot;counts&quot;, xlabel=&quot;y&quot;, ylabel=&quot;x&quot;, camera=(40,40)); xlabel!(&quot;x&quot;); ylabel!(&quot;y&quot;); title!(&quot;Histogram of shots scored&quot;) More shots are made as we get near the hoop, as expected. It is worth noting that we are not showing the probability of scoring, we are just showing the distribution of shot scored, not how likely is it to score. 8.1 Modelling the scoring probability The first model we are going to propose is a Bernoulli model. A Bernoulli distribution results from an experiment in which we have two possible outcomes, one that is usually called a success and another called a failure. In our case our success is scoring the shot and the other possible event is failing it. The only parameter needed in a bernoulli distribution is the probability \\(p\\) of having a success. We are going to model this parameter as a logistic function: plot(logistic, legend=false); xlabel!(&quot;x&quot;); ylabel!(&quot;Probability&quot;); title!(&quot;Logistic function (x)&quot;) The reason to choose a logistic function is that we are going to model the probability of shootiing as a function of some variables, for example the distance to the hoop, and we want that our scoring probability increases as we get closer to it. Also out probability needs to be between 0 an 1, so a nice function to map our values is the logistic function. The probabilistic model we are going to propose is \\(p\\sim logistic(a + b*distance[i] + c*angle[i])\\) \\(outcome[i]\\sim Bernoulli(p)\\) As you can see, this is a very general model, since we haven’t yet specified anything about \\(a\\), \\(b\\) and \\(c\\). Our approach will be to propose prior distributions for each one of them and check if our proposals make sense. 8.2 Prior Predictive Checks: Part I Lets start by proposing Normal prior distributions for \\(a\\), \\(b\\) and \\(c\\), i.e., Gaussian distributions with mean 0 and variance 1. Lets sample and see what are the possible predictions for \\(p\\): \\(a\\sim N(0,1)\\) \\(b\\sim N(0,1)\\) \\(c\\sim N(0,1)\\) possible_distances = 0:0.01:1 possible_angles = 0:0.01:π/2 n_samples = 100 # we sample possible values from a and b a_prior_sampling = rand(Normal(0,1), n_samples) b_prior_sampling = rand(Normal(0,1), n_samples) # with the sampled values of a and b, we make predictions about how p would look predicted_p = [] for i in 1:n_samples push!(predicted_p, logistic.(a_prior_sampling[i] .+ b_prior_sampling[i] .* possible_distances)) end plot(possible_distances, predicted_p[1], legend = false, color=&quot;blue&quot;); for i in 2:n_samples plot!(possible_distances, predicted_p[i], color=:blue); end xlabel!(&quot;Normalized distance&quot;); ylabel!(&quot;Predicted probability&quot;); title!(&quot;Prior predictive values for p&quot;) Each one of these plots is the result of the logistic with one combination of \\(a\\) and \\(b\\) as parameters. We see that some of the predicted values of \\(p\\) don’t make sense. For example, if \\(b\\) takes positive values, we are saying that as we increase our distance from the hoop, the probability of scoring also increases. As we want \\(b\\) to be a negative number, we should propose a distribution which we can sample from and be sure their values have always the same sign. One example of this is the LogNormal distribution, which will give us always positive numbers. Multiplying these values by \\(-1\\) gives us the certainty that we will have a negative number. We update our model as follows: \\(a\\sim Normal(0,1)\\) \\(b\\sim LogNormal(1,0.25)\\) \\(c\\sim Normal(0,1)\\) Repeating the sampling process with the updated model, we get the following predictions for \\(p\\): b_prior_sampling_negative = rand(LogNormal(1,0.25), n_samples) predicted_p_inproved = [] for i in 1:n_samples push!(predicted_p_inproved, logistic.(a_prior_sampling[i] .- b_prior_sampling_negative[i].*possible_distances)) end plot(possible_distances, predicted_p_inproved[1], legend = false, color=:blue); for i in 2:n_samples plot!(possible_distances, predicted_p_inproved[i], color=:blue); end xlabel!(&quot;Normalized distance&quot;); ylabel!(&quot;Predicted probability&quot;); title!(&quot;Prior predictive values with negative LogNormal prior&quot;) Now the behavior we can see from the predicted \\(p\\) curves is the expected. As the shooting distance increases, the probability of scoring decreases. We have set some boundaries in the form of a different prior probability distribution. This process is what is called prior-predictive checks. Esentially, it is an iterative process where we check if our initial proposals make sense. Now that we have the expected behaviour for \\(p\\), we define our model and calculate the posterior distributions with our data points. 8.2.1 Defining our model in Turing and computing posteriors Now we define our model in the Turing framework in order to sample from it: @model logistic_regression(distances, angles, result,n) = begin N = length(distances) # Set priors. a ~ Normal(0,1) b ~ LogNormal(1,0.25) c ~ Normal(0,1) for i in 1:n p = logistic(a - b*distances[i] + c*angles[i]) result[i] ~ Bernoulli(p) end end n = 1000 The output of the sampling tells us also some information about sampled values for our parameters, like the mean, the standard deviation and some other computations. # Sample using HMC. chain = mapreduce(c -&gt; sample(logistic_regression(shots.distance[1:n] ./ maximum(shots.distance[1:n] ), shots.angle[1:n], shots.result[1:n], n), NUTS(), 1500), chainscat, 1:3); 8.2.1.1 Traceplot In the plot below we show a traceplot of the sampling. When we run a model and calculate the posterior, we obtain sampled values from the posterior distributions. We can tell our sampler how many sampled values we want. A traceplot just shows them in sequential order. We also can plot the distribution of those values, and this is what is showed next to each traceplot. plot(chain, dpi=60) a_mean = mean(chain[:a]) b_mean = mean(chain[:b]) c_mean = mean(chain[:c]) Now plotting the scoring probability using the posterior distributions of \\(a\\), \\(b\\) and \\(c\\) for an angle of 45°, we get: p_constant_angle = [] for i in 1:length(chain[:a]) push!(p_constant_angle, logistic.(chain[:a][i] .- chain[:b][i].*possible_distances .+ chain[:c][i].*π/4)); end plot(possible_distances,p_constant_angle[1], legend=false, alpha=0.1, color=:blue); for i in 2:1000 plot!(possible_distances,p_constant_angle[i], alpha=0.1, color=:blue); end xlabel!(&quot;Normalized distance&quot;); ylabel!(&quot;Probability&quot;); title!(&quot;Scoring probability vs Normalized distance (angle=45°)&quot;) We clearly see how our initial beliefs got adjusted with the data. Although initially the decreasing scoring probability with increasing distance behavior was correct, there was a lot of uncertainty about the expected value. What this last plot shows is how the possible values of p narrowed as we updated our beliefs with data. We already plotted how the scoring probability changes with respect to the distance from the hoop, but what about the angle? In principle, we could think that this should not be too relevant, since there is no special advantage on changing the angle from where we make our shot, but let’s see what does our model say when showing some real data to it. Just to keep the distance constant and only take into account the angle change, we plot for a miiddle distance, i.e., \\(0.5\\) in a normalized distance. p_constant_distance = [] for i in 1:length(chain[:a]) push!(p_constant_distance, logistic.(chain[:a][i] .- chain[:b][i].*0.5 .+ chain[:c][i].*possible_angles)); end plot(rad2deg.(possible_angles), p_constant_distance[1], legend=false, alpha=0.1, color=:blue); for i in 2:1000 plot!(rad2deg.(possible_angles), p_constant_distance[i], alpha=0.1, color=:blue); end xlabel!(&quot;Angle [deg]&quot;); ylabel!(&quot;Probability&quot;); title!(&quot;Scoring probability vs Angle (mid distance)&quot;) We see that the model predicts almost constant average probability as we vary the angle. This is consistent with what we already suspected, although we see there is more uncertainty about the scoring probability as we move from 0° to 90°. In conclusion, the angle doesn’t seem too important when shooting; the distance from the hoop is the relevant variable. 8.3 New model and prior predictive checks: Part II &lt;Why was this model chosen?&gt; Now we propose another model with the form: \\(p\\sim logistic(a + b^{distance[i]} + c*angle[i])\\) *But for what values of b the model makes sense? Here we basically changed the dependence of the model with distance. We now have the parameter \\(b\\) to the power of the distance from the hoop. We should ask ourselves, like we did with the other proposed models: Would every possible value of \\(b\\) make sense? Let’s dig into this question. Below we plot four function with four different possible values of \\(b\\), having in mind that the values of \\(x\\), the normalized distance, goes from 0 to 1. These functions are f1(x) = 0.3^x f2(x) = 1.5^x f3(x) = -0.3^x f4(x) = -1.5^x and their plots are plot(0:0.01:1, f1, label=&quot;f1: b &lt; 1 &amp; b &gt; 0&quot;, xlim=(0,1), ylim=(-2,2), lw=3); plot!(0:0.01:1, f2, label=&quot;f2: b&gt;1&quot;, lw=3); plot!(0:0.01:1, f3, label=&quot;f3: b&lt;0 &amp; b&gt;-1&quot;, lw=3); plot!(0:0.01:1, f4, label=&quot;f3: b&lt;-1&quot;, lw=3); xlabel!(&quot;Normalized distance&quot;); title!(&quot;Prior Predictive influence of distance&quot;) As we can see, the qualitative behavior of these functions is different for each of the chosen values for \\(b\\). The only one of these values that is consistent with our common sense, is the one proposed for \\(f_1\\), as we want it to be a decreasing function for the distance variable. In other words, we want \\(b\\) to be in the range from 0 to 1, and to be positive. Now that we have limited the range of values that \\(b\\) can take, we should propose a probability distribution that satisfies the constraints the parameter should have. For this, we propose a Beta distribution with parameters \\(α=2\\) and \\(β=2\\). We chose these distribution since it is only defined in the interval we are interesed on, and the value of the parameters so that the distribution is symmetrical, i.e., not biased towards the start or the end of the range from 0 to 1. plot(Beta(2,2), xlim=(-0.1,1), legend=false); title!(&quot;Prior distribution for b&quot;) 8.3.1 Defining the new model and computing posteriors We define then our model and calculate the posterior as before. @model logistic_regression_exp(distances, angles, result, n) = begin N = length(distances) # Set priors. a ~ Normal(0,1) b ~ Beta(2,2) c ~ Normal(0,1) for i in 1:n p = logistic(a + b .^ distances[i] + c*angles[i]) result[i] ~ Bernoulli(p) end end ## logistic_regression_exp (generic function with 2 methods) # Sample using HMC. chain_exp = mapreduce(c -&gt; sample(logistic_regression_exp(shots.distance[1:n] ./ maximum(shots.distance[1:n] ), shots.angle[1:n], shots.result[1:n], n), HMC(0.05, 10), 1500), chainscat, 1:3) Plotting the traceplot we see again that the variable angle has little importance since the parameter \\(c\\), that can be related to the importance of the angle variable for the probability of scoring, is centered at 0. plot(chain_exp, dpi=55) p_exp_constant_angle = [] for i in 1:length(chain_exp[:a]) push!(p_exp_constant_angle, logistic.(chain_exp[:a][i] .+ chain_exp[:b][i].^possible_distances .+ chain_exp[:c][i].*π/4)) end Employing the posteriors distributions computed, we plot the probability of scoring as function of the normalized distance and obtain the plot shown below. plot(possible_distances,p_exp_constant_angle[1], legend=false, alpha=0.1, color=:blue); for i in 2:1000 plot!(possible_distances,p_exp_constant_angle[i], alpha=0.1, color=:blue); end xlabel!(&quot;Normalized distance&quot;); ylabel!(&quot;Probability&quot;); title!(&quot;Scoring probability vs Normalized distance (angle=45°)&quot;) Given that we have 2 variables, we can plot the mean probability of scoring as function of the two and obtain a surface plot, too: angle_ = collect(range(0, stop=π/2, length=100)) dist_ = collect(range(0, stop=1, length=100)) it = Iterators.product(angle_, dist_) matrix = collect.(it) values = reshape(matrix, (10000, 1)) angle_grid = getindex.(values,[1]) dist_grid = getindex.(values,[2]) z = logistic.(mean(chain_exp[:a]) .+ mean(chain_exp[:b]).^dist_grid .+ mean(chain_exp[:c]).*angle_grid) The plot shows the expected behavior, an increasing probability of scoring as we get near the hoop. We also see that there is almost no variation of the probability with the angle. 8.4 Does the Period affect the scoring probability? We have been using the scoring data across all periods, but what about how the scoring probability changes across periods? We will propose a model and calculate the posterior for its parameters with scoring data of each of the four possible periods. The exact same model for all four periods will be used. The angle variable will be discarded from the model, as we have already saw that is of little importance. We filter our data by period and proceed to estimate our posterior distributions. shots_period1 = filter(x -&gt; x.period == 1, shots) @model logistic_regression_period(distances, result,n) = begin N = length(distances) # Set priors. a ~ Normal(0,1) b ~ Beta(2,5) for i in 1:n p = logistic(a + b .^ distances[i]) result[i] ~ Bernoulli(p) end end n_ = 500 # Sample using HMC. chain_period1 = mapreduce(c -&gt; sample(logistic_regression_period(shots_period1.distance[1:n_] ./ maximum(shots_period1.distance[1:n_] ), shots_period1.result[1:n_], n_), HMC(0.05, 10), 1500), chainscat, 1:3) shots_period2 = filter(x -&gt; x.period == 2, shots) # Sample using HMC. chain_period2 = mapreduce(c -&gt; sample(logistic_regression_period(shots_period2.distance[1:n_] ./ maximum(shots_period2.distance[1:n_] ), shots_period2.result[1:n_], n_), HMC(0.05, 10), 1500), chainscat, 1:3 ); shots_period3= filter(x-&gt;x.period==3, shots); # Sample using HMC. chain_period3 = mapreduce(c -&gt; sample(logistic_regression_period(shots_period3.distance[1:n_] ./ maximum(shots_period3.distance[1:n_] ), shots_period3.result[1:n_], n_), HMC(0.05, 10), 1500), chainscat, 1:3 ); shots_period4 = filter(x-&gt;x.period==4, shots); # Sample using HMC. chain_period4 = mapreduce(c -&gt; sample(logistic_regression_period(shots_period4.distance[1:n_] ./ maximum(shots_period4.distance[1:n_]), shots_period4.result[1:n_], n_), HMC(0.05, 10), 1500), chainscat, 1:3 ); p_period1 = logistic.(mean(chain_period1[:a]) .+ mean(chain_period1[:b]).^possible_distances ) p_period1_std = logistic.((mean(chain_period1[:a]) .+ std(chain_period1[:a])) .+ (mean(chain_period1[:b]) .+ std(chain_period1[:a])).^possible_distances) p_period2 = logistic.(mean(chain_period2[:a]) .+ mean(chain_period2[:b]).^possible_distances ) p_period2_std = logistic.((mean(chain_period2[:a]) .+ std(chain_period2[:a])) .+ (mean(chain_period2[:b]) .+ std(chain_period2[:a])).^possible_distances) p_period3 = logistic.(mean(chain_period3[:a]) .+ mean(chain_period3[:b]).^possible_distances) p_period3_std = logistic.((mean(chain_period3[:a]) .+ std(chain_period3[:a])) .+ (mean(chain_period3[:b]) .+ std(chain_period3[:a])).^possible_distances) p_period4 = logistic.(mean(chain_period4[:a]) .+ mean(chain_period4[:b]).^possible_distances ) p_period4_std = logistic.((mean(chain_period4[:a]) .+ std(chain_period4[:a])) .+ (mean(chain_period4[:b]) .+ std(chain_period4[:a])).^possible_distances) We plot now for each period the probability of scoring for each period, each mean and one standard deviation from it. plot(possible_distances, p_period4,ribbon=p_period4_std.-p_period4, color=:magenta, label=&quot;period4&quot;, fillalpha=.3, ylim=(0,0.6)); plot!(possible_distances, p_period2, color=:green, ribbon=p_period2_std.-p_period2, label=&quot;period2&quot;, fillalpha=.3); plot!(possible_distances, p_period3, color=:orange, ribbon=p_period3_std.-p_period3, label=&quot;period3&quot;,fillalpha=.3); plot!(possible_distances, p_period1,ribbon=p_period1_std.-p_period1, color=:blue, label=&quot;period1&quot;, fillalpha=.3); xlabel!(&quot;Normalized distance&quot;); ylabel!(&quot;Scoring probability&quot;) Comparing the means of each period, we see that for the periods 1 and 4, the first and the last periods, the scoring probability is slightly higher than the other two periods. There are a bunch of possible explanations for these results. Clearly in the first period, players are most effective due to being with the most energy. In period 4, new players have substituted the old ones, and also have a lot of energy, while in periods 2 and 3, there is a tendency for more tired players that have not been substituted. These hypothesis should be tested to know if they are correct, but it is a starting point for more data analysis. 8.5 Summary In this chapter, we used the NBA shooting data of the season 2006-2007 to analyze how the scoring probability is affected by some variables, such as the distance from the hoop and the shooting angle. First, we inspected the data by plotting a heatplot of all the shots made and making histograms of the ones that scored. As our goal was to study the scoring probability, which is a Bernoulli trial situation, we decided to use a Bernoulli model. Since the only parameter needed in a Bernoulli distribution is the probability \\(p\\) of having a success, we modeled \\(p\\) as a logistic function: \\(p\\sim logistic(a+ b*distance[i] + c*angle[i])\\) We set the prior probability of the parameters \\(a\\) and \\(c\\) to a Normal distribution and \\(b\\) to a LogNormal one. Thus, we constructed our logistic regression model and sampled it using the Markov Monte Carlo algorithm (MCMC). To gain a better understanding of the sampling process, we made a traceplot that shows the sampled values in a sequential order. Later, we decided to try with a more complex logistic regression model, similar to the first one but this time modifying the distance dependency: \\(p\\sim logistic(a+ b^{distance[i]} + c*angle[i])\\) We set the prior distribution of \\(b\\) to a beta distribution and constructed the second logistic regression model, sampled it and plotted the results. Finally, we analyzed the results to see if the period of the game affects the scoring probability. "
    ],
    [
        "404.html",
        "Page not found",
        " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "
    ]
]